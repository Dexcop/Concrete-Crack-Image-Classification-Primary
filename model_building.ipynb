{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44c1a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.feature import local_binary_pattern, hog\n",
    "from tqdm import tqdm \n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e619efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = './dataset/'\n",
    "IMG_WIDTH = 224\n",
    "IMG_HEIGHT = 224\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6270ee42",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Getting file paths and labels')\n",
    "\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "positive_path = os.path.join(DATASET_PATH, 'Positive')\n",
    "negative_path = os.path.join(DATASET_PATH, 'Negative')\n",
    "\n",
    "for filename in os.listdir(positive_path):\n",
    "    image_paths.append(os.path.join(positive_path, filename))\n",
    "    labels.append(1)\n",
    "    \n",
    "for filename in os.listdir(negative_path):\n",
    "    image_paths.append(os.path.join(negative_path, filename))\n",
    "    labels.append(0)\n",
    "    \n",
    "image_paths = np.array(image_paths)\n",
    "labels = np.array(labels)\n",
    "\n",
    "X_train_paths, X_test_paths, y_train, y_test = train_test_split(\n",
    "    image_paths, labels, test_size=0.25, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "print(f'Training test size: {len(X_train_paths)}')\n",
    "print(f'Testing test size: {len(X_test_paths)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88108bd0",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28683415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_generator_akaze(image_paths, labels, batch_size):\n",
    "    akaze = cv2.AKAZE_create()\n",
    "    \n",
    "    num_samples = len(image_paths)\n",
    "    \n",
    "    while True:\n",
    "        indices = np.arange(num_samples)\n",
    "        np.random.shuffle(indices)\n",
    "        shuffled_paths = image_paths[indices]\n",
    "        shuffled_labels = labels[indices]\n",
    "        \n",
    "        for i in range (0, num_samples, batch_size):\n",
    "            batch_paths = shuffled_paths[i:i + batch_size]\n",
    "            batch_labels = shuffled_labels[i:i + batch_size]\n",
    "            \n",
    "            batch_features = []\n",
    "            \n",
    "            for img_path in tqdm(batch_paths, desc='Batch Progress'):\n",
    "                image = cv2.imread(img_path)\n",
    "                image = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT))\n",
    "                gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "                \n",
    "                keypoints, descriptors = akaze.detectAndCompute(gray_img, None)\n",
    "                \n",
    "                if descriptors is not None:\n",
    "                    feature_vectors = np.mean(descriptors, axis=0)\n",
    "                else:\n",
    "                    feature_vectors = np.zeros(61)\n",
    "                \n",
    "                batch_features.append(feature_vectors)\n",
    "            \n",
    "            yield np.array(batch_features), np.array(batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c799588e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification\n",
    "train_gen_akaze = feature_generator_akaze(X_train_paths, y_train, BATCH_SIZE)\n",
    "\n",
    "print('fetching one batch of feature vectors to test')\n",
    "sample_akaze_batch_features, sample_akaze_batch_labels = next(train_gen_akaze) \n",
    "\n",
    "print('pipeline complete, ready for training')\n",
    "print(f'shape of one batch of features: {sample_akaze_batch_features.shape}') # 32 per batch and 10 length\n",
    "print(f'shape of one batch of labels: {sample_akaze_batch_labels.shape}')  # 32 per batch\n",
    "print(f'example feature vector (first image in batch:\\n {sample_akaze_batch_features[0]})') # 10 arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ba1cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAINING_STEPS = len(X_train_paths) // BATCH_SIZE\n",
    "\n",
    "pipeline_generators = {\n",
    "    'AKAZE': feature_generator_akaze,\n",
    "}\n",
    "\n",
    "def extract_test_features(extractor_name, paths):\n",
    "    print(f'extracting test features for {extractor_name}')\n",
    "    \n",
    "    test_features = []\n",
    "    \n",
    "    akaze = cv2.AKAZE_create()\n",
    "    \n",
    "    for img_path in tqdm(paths, desc=f'Testing {extractor_name}'):\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT))\n",
    "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        _, descriptors = akaze.detectAndCompute(gray_image, None)\n",
    "        if descriptors is not None: \n",
    "            feature_vector = np.mean(descriptors, axis=0)\n",
    "        else:\n",
    "            feature_vector = np.zeros(61)\n",
    "        test_features.append(feature_vector)\n",
    "        \n",
    "    return np.array(test_features)\n",
    "\n",
    "results = {}\n",
    "\n",
    "for pipeline_name, generator_function in pipeline_generators.items():\n",
    "    print(f'training baseline model for: {pipeline_name}')\n",
    "    \n",
    "    model = SGDClassifier(max_iter=1000, tol=1e-3, random_state=42)\n",
    "    train_generator = generator_function(X_train_paths, y_train, BATCH_SIZE)\n",
    "    \n",
    "    for _ in tqdm(range(int(NUM_TRAINING_STEPS)), desc=f'Training {pipeline_name}'):\n",
    "        X_batch, y_batch = next(train_generator)\n",
    "        model.partial_fit(X_batch, y_batch, classes=np.array([0, 1]))\n",
    "    \n",
    "    X_test_features = extract_test_features(pipeline_name, X_test_paths)\n",
    "    y_pred = model.predict(X_test_features)\n",
    "    report = classification_report(y_test, y_pred, target_names=['No Crack (0)', 'Crack (1)'], output_dict=True)\n",
    "    results[pipeline_name] = report\n",
    "\n",
    "print('final baseline comparison report')\n",
    "\n",
    "best_pipeline = max(results, key=lambda p: results[p]['Crack (1)']['f1-score'])\n",
    "\n",
    "for pipeline_name, report in results.items():\n",
    "    f1_crack = report['Crack (1)']['f1-score']\n",
    "    print(\"==========================================\")\n",
    "    print(f\"               {pipeline_name} {'WINNER' if pipeline_name == best_pipeline else ''}\")\n",
    "    print(\"==========================================\")\n",
    "    print(f\"              precision    recall  f1-score   support\")\n",
    "    print(f\"No Crack (0)      {report['No Crack (0)']['precision']:.2f}         {report['No Crack (0)']['recall']:.2f}      {report['No Crack (0)']['f1-score']:.2f}      {report['No Crack (0)']['support']}\")\n",
    "    print(f\"   Crack (1)      {report['Crack (1)']['precision']:.2f}         {report['Crack (1)']['recall']:.2f}      {report['Crack (1)']['f1-score']:.2f}      {report['Crack (1)']['support']}\")\n",
    "    print(f\"\\n   Accuracy                           {report['accuracy']:.2f}     {report['macro avg']['support']}\")\n",
    "    print(f\"   Macro Avg      {report['macro avg']['precision']:.2f}         {report['macro avg']['recall']:.2f}      {report['macro avg']['f1-score']:.2f}      {report['macro avg']['support']}\")\n",
    "    print(f\"Weighted Avg      {report['weighted avg']['precision']:.2f}         {report['weighted avg']['recall']:.2f}      {report['weighted avg']['f1-score']:.2f}      {report['weighted avg']['support']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
